{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to mount PostgreSQL database using Apache Spark\n",
    "\n",
    "The first line sets the value of the **driver** variable to **\"org.postgresql.Driver\"**. This specifies the driver class to be used for connecting to the PostgreSQL database.\n",
    "\n",
    "- ```database_host``` refers to the hostname or IP address of the machine where the PostgreSQL database is running. It specifies the location of the database server.\n",
    "- ```database_name``` refers to the name of the database you want to connect to.\n",
    "- ```table``` refers to the name of the table within the specified PostgreSQL database from which you want to read data.\n",
    "- ```user``` and ```password``` refer to the credentials required to authenticate and authorize access to the PostgreSQL database.\n",
    "\n",
    "Replace the above values in the respective place-holders.\n",
    "\n",
    "**url** variable is then constructed using the ```database_host``` and ```database_name``` variables. It follows the format **\"jdbc:postgresql://<host>:5432/<database>\"**, where **<host>** is the value of **database_host** and **<database>** is the value of **database_name**. The port **5432** is the default port for PostgreSQL.\n",
    "\n",
    "**spark.read** function  is used to create a DataFrameReader object.\n",
    "\n",
    "**.format(\"jdbc\")** method specifies the format of the data source, which in this case is JDBC (Java Database Connectivity) for connecting to the PostgreSQL database.\n",
    "\n",
    "**.option()** method is used to set various options for the JDBC connection. These options include the driver, URL, table name, user login, and password.\n",
    "\n",
    "Finally, the **.load()** method is called to load the data from the database into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b050ce82-1a9d-4230-aa02-d51218dd51a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "driver = \"org.postgresql.Driver\"\n",
    "\n",
    "database_host = {Host_Name}\n",
    "database_name = {Database_Name}\n",
    "table = {Table_Name}\n",
    "user = {User_login}\n",
    "password = {Password}\n",
    "\n",
    "url = f\"jdbc:postgresql://{database_host}:5432/{database_name}\"\n",
    "\n",
    "remote_table = (spark.read\n",
    "  .format(\"jdbc\")\n",
    "  .option(\"driver\", driver)\n",
    "  .option(\"url\", url)\n",
    "  .option(\"dbtable\", table)\n",
    "  .option(\"user\", user)\n",
    "  .option(\"password\", password)\n",
    "  .load()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, this code sets up the necessary configuration for connecting to a **PostgreSQL database** using **JDBC** and reads data from a specified table into a DataFrame using Apache Spark."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "postgres_db",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
