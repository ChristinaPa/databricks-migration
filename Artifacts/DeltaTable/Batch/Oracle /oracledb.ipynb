{"cells":[{"cell_type":"markdown","source":["# Bronze Layer\nRead data from an *Oracle* database"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"87fb094e-891d-43e5-9187-6c9854c66dfe","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Configure the JDBC connection properties\nhostname = {Host_Name} # hostname or host IP address where the Oracle database is running\nport = {port}  # port number on which the Oracle database is listening for incoming connections. The default port for Oracle databases is usually 1521\nservice = {service_name} # unique identifier that identifies a specific Oracle service running on the database server\nuser = {user}  # username for your Oracle database\npassword = {password}  # corresponding password for your account\ndriver = \"oracle.jdbc.driver.OracleDriver\"  # Oracle JDBC driver\ntable1 = {Table1_name} # name of the first table you want to read from\ntable2 = {Table2_name} # name of the second table you want to read from\ntable3 = {Table3_name} # name of the third table you want to read from\n\njdbc_url = \"jdbc:oracle:thin:@{hostname}:{port}/{service}\" # JDBC URL required for establishing the connection to the Oracle database\n\n# Read data from the Oracle database and create Bronze tables\n\n# Create dimension1 raw Delta Live Table\n    df1 = (spark.read\n        .format(\"jdbc\")\n        .option(\"url\", jdbc_url)\n        .option(\"dbtable\", table1)\n        .option(\"user\", user)\n        .option(\"password\", password)\n        .option(\"driver\", driver)\n        .load()\n    )\n\n    ##create a table from the DataFrame\n    df1.write.format(\"delta\").saveAsTable(\"Dim1_raw\")\n    \n# Create dimension2 raw Delta Live Table\n    df2 = (spark.read\n        .format(\"jdbc\")\n        .option(\"url\", jdbc_url)\n        .option(\"dbtable\", table2)\n        .option(\"user\", user)\n        .option(\"password\", password)\n        .option(\"driver\", driver)\n        .load()\n    )\n\n    ##create a table from the DataFrame\n    df1.write.format(\"delta\").saveAsTable(\"Dim2_raw\")\n    \n# Create fact raw Delta Live Table\n    df3 = (spark.read\n        .format(\"jdbc\")\n        .option(\"url\", jdbc_url)\n        .option(\"dbtable\", table3)\n        .option(\"user\", user)\n        .option(\"password\", password)\n        .option(\"driver\", driver)\n        .load()\n    )\n    \n    ##create a table from the DataFrame\n    df3.write.format(\"delta\").saveAsTable(\"Fact_raw\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e4fffd4-e4f0-4f8d-bf19-ca4f556b9306","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"application/vnd.databricks.v1+notebook":{"notebookName":"oracledb (1)","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
