{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87fb094e-891d-43e5-9187-6c9854c66dfe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer\n",
    "Read data from an *Oracle* database\n",
    "\n",
    "#### Pre-requisite:\n",
    "Obtain the Oracle JDBC driver (JAR file) and upload it to the cluster through the Databricks UI\n",
    "1. Go to the Oracle website: https://www.oracle.com/database/technologies/appdev/jdbc-downloads.html\n",
    "\n",
    "1. Scroll down to the \"Oracle Database JDBC Driver Downloads\" section.\n",
    "\n",
    "1. Select the appropriate driver version based on your Oracle database version and Java version. Ensure that you choose the correct driver version that matches your database and Java environment.\n",
    "\n",
    "1. Click on the download link to download the JDBC driver (JAR file) to your local machine.\n",
    "\n",
    "1. Once the download is complete, you will have the Oracle JDBC driver JAR file.\n",
    "\n",
    "1. Open the Databricks workspace in your browser and navigate to the cluster where you want to upload the JAR file.\n",
    "\n",
    "1. Click on the \"Libraries\" tab in the cluster details page.\n",
    "\n",
    "1. Click on the \"Install New\" button.\n",
    "\n",
    "1. In the \"Library Source\" section, select \"Upload\".\n",
    "\n",
    "1. In the \"Library Type\" section, select \"JAR\"\n",
    "\n",
    "1. Click on the \"Drop JAR here\" button to select the JAR file from your local machine.\n",
    "\n",
    "1. Once you have selected the JAR file, click on the \"Install\" button to upload and install the JAR file on the cluster.\n",
    "\n",
    "1. Databricks will upload the JAR file and make it available for use in your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e4fffd4-e4f0-4f8d-bf19-ca4f556b9306",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure the JDBC connection properties\n",
    "hostname = {Host_Name} # hostname or host IP address where the Oracle database is running\n",
    "port = {port}  # port number on which the Oracle database is listening for incoming connections. The default port for Oracle databases is usually 1521\n",
    "service = {service_name} # unique identifier that identifies a specific Oracle service running on the database server\n",
    "user = {user}  # username for your Oracle database\n",
    "password = {password}  # corresponding password for your account\n",
    "driver = \"oracle.jdbc.driver.OracleDriver\"  # Oracle JDBC driver\n",
    "table1 = {Table1_name} # name of the first table you want to read from\n",
    "table2 = {Table2_name} # name of the second table you want to read from\n",
    "table3 = {Table3_name} # name of the third table you want to read from\n",
    "\n",
    "jdbc_url = \"jdbc:oracle:thin:@{hostname}:{port}/{service}\" # JDBC URL required for establishing the connection to the Oracle database\n",
    "\n",
    "# Read data from the Oracle database and create Bronze tables\n",
    "\n",
    "# Create dimension1 raw Delta Live Table\n",
    "    df1 = (spark.read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", jdbc_url)\n",
    "        .option(\"dbtable\", table1)\n",
    "        .option(\"user\", user)\n",
    "        .option(\"password\", password)\n",
    "        .option(\"driver\", driver)\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "    ##create a table from the DataFrame\n",
    "    df1.write.format(\"delta\").saveAsTable(\"Dim1_raw\")\n",
    "    \n",
    "# Create dimension2 raw Delta Live Table\n",
    "    df2 = (spark.read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", jdbc_url)\n",
    "        .option(\"dbtable\", table2)\n",
    "        .option(\"user\", user)\n",
    "        .option(\"password\", password)\n",
    "        .option(\"driver\", driver)\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "    ##create a table from the DataFrame\n",
    "    df1.write.format(\"delta\").saveAsTable(\"Dim2_raw\")\n",
    "    \n",
    "# Create fact raw Delta Live Table\n",
    "    df3 = (spark.read\n",
    "        .format(\"jdbc\")\n",
    "        .option(\"url\", jdbc_url)\n",
    "        .option(\"dbtable\", table3)\n",
    "        .option(\"user\", user)\n",
    "        .option(\"password\", password)\n",
    "        .option(\"driver\", driver)\n",
    "        .load()\n",
    "    )\n",
    "    \n",
    "    ##create a table from the DataFrame\n",
    "    df3.write.format(\"delta\").saveAsTable(\"Fact_raw\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "oracledb (1)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
