{"cells":[{"cell_type":"markdown","source":["## How to read schema from raw data files (Bronze layer)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3ffecd08-5108-4760-a797-d2b12fd30d27","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import * # used for data manipulation and transformation in Spark SQL\nfrom pyspark.sql.types import * # provides the data types that can be used to define the schema of a DataFrame or a column in Spark SQL\nimport datetime #imports the datetime module, which is a standard Python library for working with dates and times."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b90c5c48-a368-4ca5-a16e-2fae661e3430","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#create delta table DIm1\ndata_path1 ='/FileStore/tables/sample_emp_data.csv' # represents the file path where the data file is located ## to be changed to actual file name\ndf1 = spark.read.format(\"csv\")\\\n  .option(\"inferSchema\", \"false\")\\\n  .option(\"sep\",\",\")\\\n  .option(\"header\",\"true\")\\\n  .load(data_path1) ### read the data from the CSV file located at **data_path1** and load it into a DataFrame named **df1**\n##display(df1)\n\n## Now write out this DataFrame to a Delta table\ndf1.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Dim1_raw\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4fb5b929-b68c-40f3-9db3-1cbcd7a35940","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#create delta table Dim 2\ndata_path2 ='/FileStore/tables/sample_emp_data.csv' # represents the file path where the data file is located ## to be changed to actual file name\ndf2 = spark.read.format(\"csv\")\\\n  .option(\"inferSchema\", \"false\")\\\n  .option(\"sep\",\",\")\\\n  .option(\"header\",\"true\")\\\n  .load(data_path2) ### read the data from the CSV file located at **data_path2** and load it into a DataFrame named **df1**\n##display(df2)\n\n## Now write out this DataFrame to a Delta table\ndf2.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Dim2_raw\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"365873b2-e632-4e73-8116-35553fb47848","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#create delta table Fact Table\ndata_path3 ='/FileStore/tables/sample_emp_data.csv' # represents the file path where the data file is located ## to be changed to actual file name\ndf3 = spark.read.format(\"csv\")\\\n  .option(\"inferSchema\", \"false\")\\\n  .option(\"sep\",\",\")\\\n  .option(\"header\",\"true\")\\\n  .load(data_path3) ### read the data from the CSV file located at **data_path3** and load it into a DataFrame named **df1**\n\n##display(df3)\n\n## Now write out this DataFrame to a Delta table\ndf3.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"Fact_raw\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"76a1ad6d-798a-43c9-ab49-81e23f8686aa","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nselect * from Dim1_raw;\nselect * from Dim2_raw;\nselect * from Fact_raw;\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"309f7498-db29-42a8-b291-f16644b97963","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["9369","SMITH","CLERK","7902","12/17/1980","800","20","BANGALORE"],["9499","ALLEN","SALESMAN","7698","2/20/1981","1600","30","HYDERABAD"],["9521","WARD","SALESMAN","7698","2/22/1981","1250","30","PUNE"],["9566","TURNER","MANAGER","7839","4/2/1981","2975","20","MUMBAI"],["9654","MARTIN","SALESMAN","7698","9/28/1981","1250","30","CHENNAI"],["9369","SMITH","CLERK","7902","12/17/1980","800","20","KOLKATA"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"empno","type":"\"string\"","metadata":"{}"},{"name":"ename","type":"\"string\"","metadata":"{}"},{"name":"designation","type":"\"string\"","metadata":"{}"},{"name":"manager","type":"\"string\"","metadata":"{}"},{"name":"hire_date","type":"\"string\"","metadata":"{}"},{"name":"sal","type":"\"string\"","metadata":"{}"},{"name":"deptno","type":"\"string\"","metadata":"{}"},{"name":"location","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>empno</th><th>ename</th><th>designation</th><th>manager</th><th>hire_date</th><th>sal</th><th>deptno</th><th>location</th></tr></thead><tbody><tr><td>9369</td><td>SMITH</td><td>CLERK</td><td>7902</td><td>12/17/1980</td><td>800</td><td>20</td><td>BANGALORE</td></tr><tr><td>9499</td><td>ALLEN</td><td>SALESMAN</td><td>7698</td><td>2/20/1981</td><td>1600</td><td>30</td><td>HYDERABAD</td></tr><tr><td>9521</td><td>WARD</td><td>SALESMAN</td><td>7698</td><td>2/22/1981</td><td>1250</td><td>30</td><td>PUNE</td></tr><tr><td>9566</td><td>TURNER</td><td>MANAGER</td><td>7839</td><td>4/2/1981</td><td>2975</td><td>20</td><td>MUMBAI</td></tr><tr><td>9654</td><td>MARTIN</td><td>SALESMAN</td><td>7698</td><td>9/28/1981</td><td>1250</td><td>30</td><td>CHENNAI</td></tr><tr><td>9369</td><td>SMITH</td><td>CLERK</td><td>7902</td><td>12/17/1980</td><td>800</td><td>20</td><td>KOLKATA</td></tr></tbody></table></div>"]}}],"execution_count":0}],"metadata":{"language_info":{"name":"python"},"application/vnd.databricks.v1+notebook":{"notebookName":"bronze-layer-notebook","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":547620698368321,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
