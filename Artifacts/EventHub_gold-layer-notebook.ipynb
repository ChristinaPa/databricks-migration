{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gold layer is the final layer in the data pipeline, where the refined and transformed data resides for business intelligence and analytics purposes.\n",
    "1. The code creates a Delta table called `dim1` by reading the streaming data from the `data2_cleansed` table. It adds an identity column for surrogate key and defines the table properties, schema, and other configurations.\n",
    "2. Similarly, the code creates another Delta table called `dim2` by reading the streaming data from the `data3_cleansed` table. It also adds an identity column for surrogate key and specifies the table properties, schema, and configurations.\n",
    "3. The code then creates a fact table by joining the `data1_cleansed` table with the `dim1` and `dim2` tables. It performs inner joins on the `key_column` between the streams and selects specific columns from each table. It also computes a new column using expressions and transformations.\n",
    "4. The resulting joined data is selected and transformed, and the fact table is created with the specified table properties, comment, and configurations.\n",
    "\n",
    "Overall, the code creates dimension tables (`dim1` and `dim2`) and a fact table by joining the dimensions with the streaming data from `data1_cleansed`. The resulting tables are stored as Delta tables with the specified properties and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f343a1a4-26b9-49b7-b019-1e4ad4283d4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create dimension1 table from Delta Live Table data2_cleansed by adding identity column for surrogate key \n",
    "@dlt.table(\n",
    "    schema={gold_layer_schema},\n",
    "    comment=\"Load data to dimension1 table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def dim1():\n",
    "    return dlt.read_stream(\"data2_cleansed\")\n",
    "\n",
    "# Create dimension2 table by adding identity column for surrogate key \n",
    "@dlt.table(\n",
    "    schema={gold_layer_schema},\n",
    "    comment=\"Load data to dimension2 table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def dim2():\n",
    "    return dlt.read_stream(\"data3_cleansed\")\n",
    "\n",
    "# Create Fact Table by joining dimension tables with the third table\n",
    "@dlt.table(\n",
    "    comment=\"load data to fact table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def fact_table():\n",
    "    s = dlt.read_stream(\"data1_cleansed\").alias(\"s\")\n",
    "    p = dlt.read_stream(\"dim1\").alias(\"p\")\n",
    "    c = dlt.read_stream(\"dim2\").alias(\"c\")\n",
    "    return ( \n",
    "        # inner joins on the key_column between the streams s (representing data1_cleansed), p (representing dim1), and c (representing dim2)\n",
    "        s.join(p, s.key_column == p.key_column, \"inner\")\n",
    "        .join(c, s.key_column == c.key_column, \"inner\")\n",
    "        # computes a new column using the select() function and various transformations such as col(), alias(), and expr().\n",
    "        .select(\n",
    "            \"s.column1\",\n",
    "            \"c.column2\",\n",
    "            \"p.column3\",\n",
    "            col(\"s.old_column_name\").cast(\"date\").alias(\"new_column_name\"),\n",
    "            \"s.column4\",\n",
    "            \"s.column5\",\n",
    "            expr(\"s.column4 * s.column5\").alias(\"new_column_name\"),\n",
    "        )\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EventHub_gold-layer-notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
