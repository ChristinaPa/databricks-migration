{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45587948-7c5e-4161-82c6-35501ecf86df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0497046-c966-4ce8-b052-ae105960c161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_schema = \"customer_id integer,tax_id STRING,tax_code STRING, customer_name STRING,state STRING,city STRING,postcode STRING,street STRING,number STRING,unit STRING,region STRING,district STRING,lon double,lat double,ship_to_address STRING,valid_from STRING,valid_to STRING,units_purchased STRING,loyalty_segment integer, customer_key BIGINT\"\n",
    "\n",
    "customers_df = spark.read \\\n",
    "        .format(\"delta\") \\\n",
    "        .load(\"dbfs:/user/hive/warehouse/example.db/customers_cleansed_dt\")\n",
    "\n",
    "customers_df = customers_df.withColumn(\"customer_key\", expr(\"monotonically_increasing_id() + 1\"))\n",
    "\n",
    "dim_customers = spark.createDataFrame(customers_df.rdd, customers_schema)\n",
    "\n",
    "dim_customers.write.format(\"delta\").saveAsTable(\"example.dim_customers_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39b487a-e577-4388-bd36-3b356b15e441",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "products_schema = \"product_id STRING,product_category STRING,product_name STRING,sales_price STRING,ean13 DOUBLE,ean5 STRING,product_unit STRING, product_key BIGINT\"\n",
    "\n",
    "products_df = spark.read \\\n",
    "        .format(\"delta\") \\\n",
    "        .load(\"dbfs:/user/hive/warehouse/example.db/products_cleansed_dt\") \\\n",
    "        .select(\"product_id\", \"product_category\", \"product_name\", \"sales_price\", \"ean13\", \"ean5\", \"product_unit\")\n",
    "\n",
    "products_df = products_df.withColumn(\"product_key\", expr(\"monotonically_increasing_id() + 1\"))\n",
    "\n",
    "dim_products = spark.createDataFrame(products_df.rdd, products_schema)\n",
    "\n",
    "dim_products.write.format(\"delta\").saveAsTable(\"example.dim_products_dt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a788614e-249e-437c-bd61-cc891f3faf48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "s = spark.read.format(\"delta\").load(\"dbfs:/user/hive/warehouse/example.db/sales_orders_cleansed_dt\").alias(\"s\")\n",
    "p = spark.read.format(\"delta\").load(\"dbfs:/user/hive/warehouse/example.db/dim_products_dt\").alias(\"p\")\n",
    "c = spark.read.format(\"delta\").load(\"dbfs:/user/hive/warehouse/example.db/dim_customers_dt\").alias(\"c\")\n",
    "\n",
    "fact_sales_orders = s.join(p, s.product_id == p.product_id, \"inner\") \\\n",
    "        .join(c, s.customer_id == c.customer_id, \"inner\") \\\n",
    "        .select(\n",
    "            \"s.order_number\",\n",
    "            \"c.customer_key\",\n",
    "            \"p.product_key\",\n",
    "            col(\"s.order_datetime\").cast(\"date\").alias(\"order_date\"),\n",
    "            \"s.unit_price\",\n",
    "            \"s.quantity\",\n",
    "            expr(\"s.unit_price * s.quantity\").alias(\"total_price\"),\n",
    "        )\n",
    "\n",
    "\n",
    "fact_sales_orders.write.format(\"delta\").saveAsTable(\"example.fact_sales_orders_dt\")\n",
    "\n",
    "\n",
    "fact_customer_sales = s.join(p, s.product_id == p.product_id, \"inner\") \\\n",
    "        .join(c, s.customer_id == c.customer_id, \"inner\") \\\n",
    "        .groupBy(\"c.customer_key\", \"p.product_key\") \\\n",
    "        .agg(\n",
    "            sum(\"quantity\").alias(\"total_quantity\"),\n",
    "            sum(expr(\"s.unit_price * s.quantity\")).alias(\"sale_amount\"),\n",
    "        )\n",
    "\n",
    "\n",
    "fact_customer_sales.write.format(\"delta\").saveAsTable(\"example.fact_customer_sales_dt\")   "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gold-layer-notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
