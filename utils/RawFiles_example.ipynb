{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b31568f-5487-4807-803a-643e13080e4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs ={\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "          \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "          \"fs.azure.account.oauth2.client.id\":\"{Client ID}\",\n",
    "          \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope=\"{keyvault name}\",key=\"{client secret name}\"),\n",
    "          \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/{Directory ID}/oauth2/token\" }\n",
    "try:\n",
    "    dbutils.fs.mount(\n",
    "    source=\"abfss://data@{Storage Account Name}.dfs.core.windows.net/\",\n",
    "    mount_point=\"/mnt/data/\",\n",
    "    extra_configs = configs)\n",
    "except Exception as e:\n",
    "    print (\"Error: {} already mounted.Run unmount first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e96ed48f-1d27-4559-844e-fa7f3c4b45b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import datetime\n",
    "\n",
    "#create streaming delta live table\n",
    "salesorderstreampath ='/mnt/data/'\n",
    "df = spark.read.json(salesorderstreampath)\n",
    "@dlt.table(\n",
    "    comment=\"the streaming raw dataset.\"\n",
    "    )\n",
    "    \n",
    "def sales_orders_stream_raw():\n",
    "    return spark.readStream.schema(df.schema).json(salesorderstreampath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95a66557-bb5c-4c40-8b78-bdfbdcabc6af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# customers raw delta live table \n",
    "customerpath='/mnt/data/customers/customers.parquet'\n",
    "@dlt.table(\n",
    "    comment=\"the customers raw dataset.\"\n",
    "    )\n",
    "def customers_raw():\n",
    "    return (spark.read.parquet(customerpath,header=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df4cd482-603e-4117-bc32-bfdcaa6288ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#products raw delta live table\n",
    "productpath ='/mnt/data/products/products.parquet' \n",
    "@dlt.table(\n",
    "    comment=\"the prdduct raw dataset.\"\n",
    "    )\n",
    "def products_raw():\n",
    "    return (spark.read.parquet(productpath,header=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37bb99b2-fe2d-4928-9027-2457e5d3a552",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sales order batch raw delta live table\n",
    "salesorderbatchpath='/mnt/data/sales_orders/sales_orders.parquet' \n",
    "@dlt.table(\n",
    "    comment=\"the sales order batch raw dataset..\"\n",
    "    )\n",
    "def sales_orders_batch_raw():\n",
    "    return (spark.read.parquet(salesorderbatchpath,header=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20f0153c-c066-4185-86d3-fb809b1556b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    sales_orders_schema = StructType(\n",
    "    [\n",
    "        StructField(\"customer_id\", LongType(), True),\n",
    "        StructField(\"customer_name\", StringType(), True),\n",
    "        StructField(\"order_datetime\", StringType(), True),\n",
    "        StructField(\"order_number\", LongType(), True),\n",
    "        StructField(\n",
    "            \"ordered_products\",\n",
    "            ArrayType(\n",
    "                StructType(\n",
    "                    [\n",
    "                        StructField(\"curr\", StringType(), True),\n",
    "                        StructField(\"id\", StringType(), True),\n",
    "                        StructField(\"name\", StringType(), True),\n",
    "                        StructField(\"price\", IntegerType(), True),\n",
    "                        StructField(\"qty\", IntegerType(), True),\n",
    "                        StructField(\"unit\", StringType(), True),\n",
    "                        StructField(\n",
    "                            \"promotion_info\",\n",
    "                            StructType(\n",
    "                                [\n",
    "                                    StructField(\"promo_id\", IntegerType(), True),\n",
    "                                    StructField(\"promo_qty\", IntegerType(), True),\n",
    "                                    StructField(\"promo_disc\", DecimalType(3, 2), True),\n",
    "                                    StructField(\"promo_item\", StringType(), True),\n",
    "                                ]\n",
    "                            ),\n",
    "                            True,\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "                True,\n",
    "            ),\n",
    "            True,\n",
    "        ),\n",
    "        StructField(\"number_of_line_items\", LongType(), True),\n",
    "        StructField(\n",
    "            \"clicked_items\", ArrayType(ArrayType(StringType(), True), True), True\n",
    "        ),\n",
    "        StructField(\n",
    "            \"promo_info\",\n",
    "            ArrayType(\n",
    "                StructType(\n",
    "                    [\n",
    "                        StructField(\"promo_id\", IntegerType(), True),\n",
    "                        StructField(\"promo_qty\", IntegerType(), True),\n",
    "                        StructField(\"promo_disc\", DecimalType(3, 2), True),\n",
    "                        StructField(\"promo_item\", StringType(), True),\n",
    "                    ]\n",
    "                ),\n",
    "                True,\n",
    "            ),\n",
    "            True,\n",
    "        ),\n",
    "    ]\n",
    ") \n",
    "@dlt.table(\n",
    "    comment=\"Load data to sales_orders cleansed table\",\n",
    "    table_properties={\"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def sales_orders_cleansed():\n",
    "    return (\n",
    "        dlt.readStream(\"sales_orders_stream_raw\")        \n",
    "        .select(get_json_object(to_json(col(\"payload\")), \"$.after\").alias(\"row\"))\n",
    "        .withColumn(\"row\", regexp_replace(\"row\", '\"\\\\[', \"[\"))\n",
    "        .withColumn(\"row\", regexp_replace(\"row\", '\\\\]\"', \"]\"))\n",
    "        .withColumn(\"row\", regexp_replace(\"row\", \"\\\\\\\\\", \"\"))\n",
    "        .select(from_json(col(\"row\"), sales_orders_schema).alias(\"row\"))\n",
    "        .select(\"row.*\")\n",
    "        .withColumn(\"ordered_products\", explode(\"ordered_products\"))\n",
    "        .withColumn(\"order_datetime\", from_unixtime(\"order_datetime\"))\n",
    "        .withColumn(\"product_id\", col(\"ordered_products\").id)\n",
    "        .withColumn(\"unit_price\", col(\"ordered_products\").price)\n",
    "        .withColumn(\"quantity\", col(\"ordered_products\").qty)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "533a9244-61be-4694-a494-07f8cfde6f16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   schema = ArrayType(\n",
    "    StructType(\n",
    "        [\n",
    "            StructField(\"qty\", IntegerType(), True),\n",
    "            StructField(\"unit\", StringType(), True),\n",
    "            StructField(\"curr\", StringType(), True),\n",
    "            StructField(\"id\", StringType(), True),\n",
    "            StructField(\"name\", StringType(), True),\n",
    "            StructField(\"price\", IntegerType(), True),\n",
    "            StructField(\n",
    "                \"promotion_info\",\n",
    "                StructType(\n",
    "                    [\n",
    "                        StructField(\"promo_id\", IntegerType(), True),\n",
    "                        StructField(\"promo_qty\", IntegerType(), True),\n",
    "                        StructField(\"promo_disc\", DecimalType(3, 2), True),\n",
    "                        StructField(\"promo_item\", StringType(), True),\n",
    "                    ]\n",
    "                ),\n",
    "                True,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "schema2 = ArrayType(\n",
    "    StructType(\n",
    "        [\n",
    "            StructField(\"promo_id\", IntegerType(), True),\n",
    "            StructField(\"promo_qty\", IntegerType(), True),\n",
    "            StructField(\"promo_disc\", DecimalType(3, 2), True),\n",
    "            StructField(\"promo_item\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    "    True,\n",
    ")\n",
    "schema3 = ArrayType(ArrayType(StringType(), True), True)\n",
    "\n",
    "@dlt.table(\n",
    "    comment=\"Load data to customers cleansed table\",\n",
    "    table_properties={\"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "\n",
    "def sales_orders_batch_cleansed():\n",
    "    return (\n",
    "        dlt.read(\"sales_orders_batch_raw\")\n",
    "        .select(\"*\")\n",
    "        .withColumn(\"clicked_items\", from_json(col(\"clicked_items\"), schema3))\n",
    "        .withColumn(\"promo_info\", from_json(col(\"promo_info\"), schema2))\n",
    "        .withColumn(\"ordered_products\", from_json(col(\"ordered_products\"), schema))\n",
    "        .withColumn(\"ordered_products\", explode(\"ordered_products\"))\n",
    "        .withColumn(\"order_datetime\", from_unixtime(\"order_datetime\"))\n",
    "        .withColumn(\"product_id\", col(\"ordered_products\").id)\n",
    "        .withColumn(\"unit_price\", col(\"ordered_products\").price)\n",
    "        .withColumn(\"quantity\", col(\"ordered_products\").qty)\n",
    "    )\n",
    "    \n",
    "def customers_cleansed():\n",
    "    return (\n",
    "        dlt.read(\"customers_raw\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71170312-0f9a-4a3d-861d-7af18ba4d843",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   @dlt.table(\n",
    "    comment=\"Load data to a products cleansed table\",\n",
    "    table_properties={\"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcab01cd-cef8-46e6-bf8e-1e14d6f84dc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "   import dlt\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "@dlt.view(spark_conf={\"pipelines.incompatibleViewCheck.enabled\": \"false\"})\n",
    "def users():\n",
    "  return spark.readStream.format(\"delta\").option(\"ignoreChanges\", \"true\").table(\"retail_org.sales_orders_batch_cleansed\")\n",
    "\n",
    "dlt.create_streaming_live_table(\"sales_orders_cleansed\")\n",
    "\n",
    "dlt.apply_changes(\n",
    "  target = \"sales_orders_cleansed\",\n",
    "  source = \"users\",\n",
    "  keys = [\"order_number\"],\n",
    "  sequence_by = col(\"order_datetime\"),\n",
    "  stored_as_scd_type = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f27c62d-00e4-423f-b3c6-447920dea3e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    @dlt.table(\n",
    "    schema=\"\"\"\n",
    "         product_key BIGINT GENERATED ALWAYS AS identity,\n",
    "         product_id STRING,\n",
    "         product_category STRING,\n",
    "         product_name STRING,\n",
    "         sales_price STRING,\n",
    "         ean13 DOUBLE,\n",
    "         ean5 STRING,\n",
    "         product_unit STRING    \n",
    "    \"\"\",\n",
    "    comment=\"Load data to products dimension table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def dim_products():\n",
    "    return dlt.read(\"products_cleansed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcb7695d-18bb-4ac7-ae1d-c70efbffffb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    schema=\"\"\"\n",
    "          customer_key BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "          customer_id integer,\n",
    "          tax_id STRING,\n",
    "          tax_code STRING,\n",
    "          customer_name STRING,\n",
    "          state STRING,\n",
    "          city STRING,\n",
    "          postcode STRING,\n",
    "          street STRING,\n",
    "          number STRING,\n",
    "          unit STRING,\n",
    "          region STRING,\n",
    "          district STRING,\n",
    "          lon double,\n",
    "          lat double,\n",
    "          ship_to_address STRING,\n",
    "          valid_from STRING,\n",
    "          valid_to STRING,\n",
    "          units_purchased STRING,\n",
    "          loyalty_segment integer\n",
    "    \"\"\",\n",
    "    comment=\"Load data to customers dimension table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def dim_customers():\n",
    "    return dlt.read(\"customers_cleansed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "124f92d4-757a-423d-9b6a-e5c741cd1936",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"load data to sales orders fact table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def fact_sales_orders():\n",
    "    s = dlt.read(\"sales_orders_cleansed\").alias(\"s\")\n",
    "    p = dlt.read(\"dim_products\").alias(\"p\")\n",
    "    c = dlt.read(\"dim_customers\").alias(\"c\")\n",
    "    return (\n",
    "        s.join(p, s.product_id == p.product_id, \"inner\")\n",
    "        .join(c, s.customer_id == c.customer_id, \"inner\")\n",
    "        .select(\n",
    "            \"s.order_number\",\n",
    "            \"c.customer_key\",\n",
    "            \"p.product_key\",\n",
    "            col(\"s.order_datetime\").cast(\"date\").alias(\"order_date\"),\n",
    "            \"s.unit_price\",\n",
    "            \"s.quantity\",\n",
    "            expr(\"s.unit_price * s.quantity\").alias(\"total_price\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6c6d26d-e703-4ee0-994a-b9e52357ab75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    comment=\"load data to customer sales fact table\",\n",
    "    table_properties={\"quality\": \"gold\", \"pipelines.reset.allowed\": \"true\"},\n",
    "    spark_conf={\"pipelines.trigger.interval\": \"60 seconds\"},\n",
    "    temporary=False,\n",
    ")\n",
    "def fact_customer_sales():\n",
    "    s = dlt.read(\"sales_orders_cleansed\").alias(\"s\")\n",
    "    p = dlt.read(\"dim_products\").alias(\"p\")\n",
    "    c = dlt.read(\"dim_customers\").alias(\"c\")\n",
    "    return (\n",
    "        s.join(p, s.product_id == p.product_id, \"inner\")\n",
    "        .join(c, s.customer_id == c.customer_id, \"inner\")\n",
    "        .groupBy(\"c.customer_key\", \"p.product_key\")\n",
    "        .agg(\n",
    "            sum(\"quantity\").alias(\"total_quantity\"),\n",
    "            sum(expr(\"s.unit_price * s.quantity\")).alias(\"sale_amount\"),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RawFiles_example",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
